{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 案例：人脸图像皮肤分割\n",
    "\n",
    "**本案例需要在桌面交互式环境下操作**\n",
    "\n",
    "<img src=\"./img/interactive.jpg\" width=\"70%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 案例概要\n",
    "\n",
    "目前为止，我们已经学会了如何识别脸部和眼睛，但我们如何剪掉皮肤区域呢？在本案例中，你将使用 GrabCut 技术实现人脸图像的皮肤分割。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 案例目标\n",
    "\n",
    "在本案例中，我们将首先创建一个正面人脸级联分类器来检测人脸。使用  GrabCut 将人脸皮肤作为前景，将图像中的其他元素作为背景，实现人脸图像皮肤分割，您还可以使用前面的实验作为参考，使用鼠标修改蒙版。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 案例详细操作说明\n",
    "\n",
    "1. 导入 OpenCV 和 NumPy 模块。\n",
    "2. 添加 `Sketcher` 鼠标通用类代码，因为我们将使用它来修改 GrabCut 获得的蒙版。\n",
    "3. 使用 `cv2.imread` 函数读取输入图像，`grabcut.jpg`。数据路径为：`./data/grabcut.jpg`，注意：请以数据实际存储路径为准。\n",
    "4. 使用 `cv2.cvtColor` 函数，将 BGR 图像转换为灰度模式。\n",
    "5. 使用 `cv2.CascadeClassifier` 函数加载 Haar 级联，用于正面人脸检测。Haar 级联模型存储路径为：`./data/haarcascade_frontalface_default.xml`，注意：请以数据实际存储路径为准。\n",
    "6. 使用级联分类器 `detectMultiScale` 函数，检测图像中的人脸使用。选择参数值，检测正确的人脸。\n",
    "7. 使用上一步中获得的边界框，从图像中裁剪人脸。\n",
    "8. 调整图像尺寸为原图的两倍。使用 `cv2.resize` 函数，我们现在将处理这个调整尺寸后的图像。\n",
    "9. 你还可以使用 ROI 进一步选取人脸中的特定皮肤区域，如下图：\n",
    "<img src=\"img/ROI_07.png\" width=\"15%\">\n",
    "\n",
    "10. 使用 `cv2.grabCut` 函数获取掩码。样本结果应该类似于下图:\n",
    "<img src=\"img/25.jpg\" width=\"35%\">\n",
    "\n",
    "11. 将确认的背景和可能的背景像素划入为背景像素。下图显示了示例结果:\n",
    "<img src=\"img/26.jpg\" width=\"35%\">\n",
    "\n",
    "12. 将新蒙版与图像相乘，获得前景。\n",
    "\n",
    "13. 通过鼠标交互式微调，获得一个修改后的蒙版和最后的皮肤区域。下图显示了蒙版的示例效果：\n",
    "<img src=\"img/27.jpg\" width=\"35%\">\n",
    "\n",
    "14. 分割后的皮肤效果示例如下:\n",
    "<img src=\"img/28.jpg\" width=\"35%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 案例小结\n",
    "\n",
    "在本案例中，你实现了对人脸图像进行皮肤分割。在美妆类增强现实应用中，经常需要对用户头发 - 面部皮肤区域进行分割，通过替换各种美妆效果增强用户体验。另一方面，在临床医学应用上，恶性黑色素瘤在疾病的早期并不明显，很难通过肉眼观察来诊断。皮肤镜检查是目前早期诊断恶性黑色素瘤的最佳方法，皮肤镜手术也是通过解剖消除恶性黑色素瘤威胁的常用方法。然而，当医生使用皮肤镜图像进行诊断和治疗时，人工检查皮肤镜图像通常非常耗时和主观。因此，计算机辅助诊断 (CAD) 方法是必要的，可以大大提高诊断的效率和准确性。目前，在医学图像分割中，UNET 是最流行的网络架构，已被广泛用于各种医学成像模式以及许多分割任务。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 案例答案"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 导入库\n",
    "\n",
    "导入 OpenCV 模块和 numpy 模块。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 定义鼠标通用类\n",
    "\n",
    "OpenCV 中对于鼠标的动作有如下：\n",
    "\n",
    "- *EVENT_MOUSEMOVE 0*：# 滑动\n",
    "- *EVENT_LBUTTONDOWN 1*：# 左键点击\n",
    "- *EVENT_RBUTTONDOWN 2*：# 右键点击\n",
    "- *EVENT_MBUTTONDOWN 3*：# 中键点击\n",
    "- *EVENT_LBUTTONUP 4*：# 左键放开\n",
    "- *EVENT_RBUTTONUP 5*：# 右键放开\n",
    "- *EVENT_MBUTTONUP 6*：# 中键放开\n",
    "- *EVENT_LBUTTONDBLCLK 7*：# 左键双击\n",
    "- *EVENT_RBUTTONDBLCLK 8*：# 右键双击\n",
    "- *EVENT_MBUTTONDBLCLK 9*：# 中键双击\n",
    "\n",
    "在鼠标操作函数中，当满足鼠标左键点击然后进行拖拽的话，就会调用 `cv2.line` 函数进行线的绘制。\n",
    "\n",
    "```python\n",
    "img = cv2.line(img, pt1, pt2, color[, thickness[, lineType[, shift]]])\n",
    "```\n",
    "\n",
    "**参数说明**\n",
    "\n",
    "- **img**：背景图\n",
    "- **pt1**：直线起点坐标\n",
    "- **pt2**：直线终点坐标\n",
    "- **color**：当前绘画的颜色。如在 BGR 模式下，传递 `(255,0,0)` 表示蓝色画笔。灰度图下，只需要传递亮度值即可。\n",
    "- **thickness**：画笔的粗细，线宽。若是 `-1` 表示画封闭图像，如填充的圆。默认值是 `1`\n",
    "- **lineType**：线条的类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sketcher:\n",
    "    def __init__(self, windowname, dests, colors_func):\n",
    "        self.prev_pt = None\n",
    "        self.windowname = windowname\n",
    "        self.dests = dests\n",
    "        self.colors_func = colors_func\n",
    "        self.dirty = False\n",
    "        self.show()\n",
    "        cv2.setMouseCallback(self.windowname, self.on_mouse)\n",
    "\n",
    "    def show(self):\n",
    "        cv2.imshow(self.windowname, self.dests[0])\n",
    "        cv2.imshow(self.windowname + \": mask\", self.dests[1])\n",
    "\n",
    "    # 鼠标操作函数\n",
    "    def on_mouse(self, event, x, y, flags, param):\n",
    "        pt = (x, y)\n",
    "        if event == cv2.EVENT_LBUTTONDOWN:\n",
    "            self.prev_pt = pt\n",
    "        elif event == cv2.EVENT_LBUTTONUP:\n",
    "            self.prev_pt = None\n",
    "        if self.prev_pt and flags & cv2.EVENT_FLAG_LBUTTON:\n",
    "            for dst, color in zip(self.dests, self.colors_func()):\n",
    "                cv2.line(dst, self.prev_pt, pt, color, 5)\n",
    "            self.dirty = True\n",
    "            self.prev_pt = pt\n",
    "            self.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 加载图片\n",
    "\n",
    "调用 `cv2.imread` 函数进行图片的加载。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置输入输出路径\n",
    "import os\n",
    "base_path = os.environ.get(\"BASE_PATH\",'../data/')\n",
    "data_path = os.path.join(base_path + \"lab5/\")\n",
    "result_path = \"result/\"\n",
    "os.makedirs(result_path, exist_ok=True)\n",
    "\n",
    "\n",
    "img = cv2.imread(\"./data/grabcut.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 灰度图转换\n",
    "\n",
    "调用 `cv2.cvtColor` 将加载图片转换为灰度图。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 加载级联分类器\n",
    "\n",
    "调用 `cv2.CascadeClassifier` 加载级联分类器。加载函数如下：\n",
    "\n",
    "```python\n",
    "<CascadeClassifier object> = cv2.CascadeClassifier(filename)\n",
    "```\n",
    "其中，`filename` 是分类器的路径和名称。\n",
    "\n",
    "Hear 级联分类器多达几十种，且随着版本的更新还在不断增加。提供了对多种对象的检测功能，部分级联分类器如下表所示：\n",
    "\n",
    "|XML文件名|级联分类器类型|\n",
    "|:---|:---|\n",
    "|harrcascade_eye.xml|眼睛检测|\n",
    "|harrcascade_eye_tree_eyeglasses.xml|眼镜检测|\n",
    "|harrcascade_mcs_nose.xml|鼻子检测|\n",
    "|harrcascade_mcs_mouth.xml|嘴巴检测|\n",
    "|harrcascade_smile.xml|微笑检测|\n",
    "|harrcascade_pedestrians.xml|行人检测|\n",
    "|harrcascade_frontalface.xml|正面人脸检测|\n",
    "|harrcascade_profileface.xml|人脸检测|\n",
    "|harrcascade_silverware.xml|金属检测|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "haarCascadePath = \"./data/haarcascade_frontalface_default.xml\"\n",
    "haarCascade = cv2.CascadeClassifier(haarCascadePath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. 人脸检测\n",
    "\n",
    "使用级联分类器检测灰度图的人脸。当分类器加载完成，调用 `cv2.CascadeClassifier.detectMultiScale()` 函数，可以检测出图片中的所有人脸。\n",
    "\n",
    "函数形式如下：\n",
    "\n",
    "```python\n",
    "detectedObjects = cv2.CascadeClassifier.detectMultiScale(image, \n",
    "                                                         [scaleFactor,minNeighbors, flags, minSize, maxSize])\n",
    "```\n",
    "\n",
    "唯一必需的是 `image`，该图像是要在其中检测面部的灰度输入图像。可选参数如下：\n",
    "\n",
    "- **`scaleFactor`：** 决定每次迭代将图像调整大小的程度。这有助于检测输入图像中存在的不同大小的面部。 \n",
    "- **`minNeighbors`：** 用于确定检测目标时必须考虑的最小邻居的数量，默认为 `3`。表明被检测出来的目标的旁边至少还需要有多少个类似的目标，其作用是避免模型将背景中的人脸也作为识别的对象。\n",
    "- **`flag`：** 在新的分类器上面已经没有作用，主要是用于告诉分类器跳过平滑（无边缘区域）。\n",
    "- **`minSize`** 和 **`maxSize`：** 指定要检测的脸部的最小和最大尺寸，超出此范围的人脸都会被忽略。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "detectedFaces = haarCascade.detectMultiScale(gray, 1.2, 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. 选出第一个人脸\n",
    "\n",
    "从检测的所有人脸中，选择其中第一个人脸，并使用切片的方式将人脸提取出来。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y,w,h = detectedFaces[0]\n",
    "img = img[y:y+h, x:x+w]\n",
    "imgCopy = img.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. 参数设置\n",
    "\n",
    "设置两个参数，宽和高。参数值为截取的人脸图片的两倍，方便后面的尺寸变换。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_percent = 200\n",
    "# 新的宽\n",
    "width = int(img.shape[1] * scale_percent/100)\n",
    "# 新的高\n",
    "height = int(img.shape[0] * scale_percent/100)\n",
    "# 新的维度\n",
    "dim = (width, height)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. 尺寸变换\n",
    "\n",
    "利用上面设置的参数，调用 `cv2.resize` 函数将截取的人脸图像进行变换。\n",
    "\n",
    "```python \n",
    "dst = resize(src, dsize[, dst[, fx[, fy[, interpolation]]]])\n",
    "```\n",
    "**参数说明**\n",
    "- **src**：输入图片\n",
    "- **dst**：输出图片\n",
    "- **dsize**：输出图片的尺寸\n",
    "- **fx**, **fy**：沿 x 轴，y 轴的缩放系数\n",
    "- **interpolation**：插入方式。插值方式有多种\n",
    "    1. *INTER_NEAREST*：最近邻插值\n",
    "    2. *INTER_LINEAR*：双线性插值（默认设置）\n",
    "    3. *INTER_AREA*：使用像素区域关系进行重采样。\n",
    "    4. *INTER_CUBIC*：`4x4` 像素邻域的双三次插值\n",
    "    5. *INTER_LANCZOS4*：`8x8` 像素邻域的 Lanczos 插值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. 显示图片（<font style='color:red'>按Esc退出</font>）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imshow(\"Face Detected\", img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/face_07.png\" width=\"20%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. 创建掩码\n",
    "\n",
    "创建一个和变换的人脸图像尺寸一致的掩码，掩码像素值都使用 `0` 填充。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.zeros(img.shape[:2], np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. 设置临时参数\n",
    "\n",
    "主要是为后面实现交互式前景提供参数，两个数组为算法内部的使用数组，只需要创建大小为 `(1,65)` 的 `numpy.float64` 数组。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bgdModel = np.zeros((1,65),np.float64)\n",
    "fgdModel = np.zeros((1,65),np.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13. 选择感兴趣区域\n",
    "调用`cv2.selectROI`手动选择感兴趣区域（<font style='color:red'>选择后按Esc退出</font>）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rect = cv2.selectROI(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/ROI_07.png\" width=\"20%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14. 输出 ROI 信息\n",
    "\n",
    "ROI 信息包括左上角坐标，矩形框的长和宽。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y,w,h = rect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15. 绘制矩形框\n",
    "\n",
    "调用 `cv2.rectangle` 函数，根据左上角坐标和右下角坐标绘制出矩形框。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.rectangle(imgCopy, (x, y), (x+w, y+h), (0, 0, 255), 3);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 16. 交互式前景提取\n",
    "\n",
    "调用 `cv2.grabCut` 函数进行交互式前景提取。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]], dtype=uint8),\n",
       " array([[ 2.57493941e-01,  1.80790000e-01,  1.81470301e-01,\n",
       "          2.02219482e-01,  1.78026277e-01,  1.72404227e+01,\n",
       "          1.96545575e+01,  2.54933950e+01,  1.50207432e+02,\n",
       "          1.65018109e+02,  1.89200376e+02,  9.33926898e+01,\n",
       "          1.03339503e+02,  1.18244611e+02,  4.72363331e+01,\n",
       "          5.66770395e+01,  7.45971405e+01,  1.85688799e+02,\n",
       "          2.02213757e+02,  2.41427991e+02,  8.04177583e+01,\n",
       "          7.59588779e+01,  6.82803198e+01,  7.59588779e+01,\n",
       "          8.01864819e+01,  7.96565691e+01,  6.82803198e+01,\n",
       "          7.96565691e+01,  1.13182585e+02,  1.31377447e+03,\n",
       "          8.86851606e+02,  2.83196441e+02,  8.86851606e+02,\n",
       "          6.51708750e+02,  3.21028827e+02,  2.83196441e+02,\n",
       "          3.21028827e+02,  4.61284402e+02,  3.51613836e+02,\n",
       "          1.83526943e+02, -3.72303112e+01,  1.83526943e+02,\n",
       "          1.70216275e+02,  1.66297460e+02, -3.72303112e+01,\n",
       "          1.66297460e+02,  5.51151506e+02,  1.78747343e+02,\n",
       "          1.67717201e+02,  1.58889154e+02,  1.67717201e+02,\n",
       "          2.23086613e+02,  2.90576368e+02,  1.58889154e+02,\n",
       "          2.90576368e+02,  5.03059740e+02,  1.96426440e+02,\n",
       "          1.38990094e+02,  9.38690406e+01,  1.38990094e+02,\n",
       "          1.08367731e+02,  7.70788029e+01,  9.38690406e+01,\n",
       "          7.70788029e+01,  6.43699640e+01]]),\n",
       " array([[2.57379662e-01, 1.33630858e-01, 3.17245776e-01, 5.99298693e-02,\n",
       "         2.31813835e-01, 1.69185782e+02, 1.85296507e+02, 2.30317810e+02,\n",
       "         6.13129771e+01, 7.44160305e+01, 1.13183206e+02, 1.29693730e+02,\n",
       "         1.47863344e+02, 1.90833601e+02, 3.01531915e+01, 3.86680851e+01,\n",
       "         6.20851064e+01, 9.60858086e+01, 1.12115237e+02, 1.48904290e+02,\n",
       "         2.58387085e+02, 2.22416552e+02, 1.93985544e+02, 2.22416552e+02,\n",
       "         1.99650751e+02, 1.68666976e+02, 1.93985544e+02, 1.68666976e+02,\n",
       "         1.63430580e+02, 1.71298992e+02, 1.75854525e+02, 1.24158310e+02,\n",
       "         1.75854525e+02, 2.09281117e+02, 1.34879888e+02, 1.24158310e+02,\n",
       "         1.34879888e+02, 1.86565672e+02, 2.02103144e+02, 1.82505574e+02,\n",
       "         1.94741642e+02, 1.82505574e+02, 1.96962033e+02, 1.80941087e+02,\n",
       "         1.94741642e+02, 1.80941087e+02, 2.14886299e+02, 2.22921213e+02,\n",
       "         2.11629570e+02, 1.75701856e+02, 2.11629570e+02, 2.26511109e+02,\n",
       "         2.14606971e+02, 1.75701856e+02, 2.14606971e+02, 2.71303395e+02,\n",
       "         9.45740450e+01, 8.38407718e+01, 6.95783447e+01, 8.38407718e+01,\n",
       "         1.01038151e+02, 8.58457377e+01, 6.95783447e+01, 8.58457377e+01,\n",
       "         1.46689960e+02]]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.grabCut(img,mask,rect,bgdModel,fgdModel,5,cv2.GC_INIT_WITH_RECT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 17. 背景提取\n",
    "\n",
    "调用 `np.where` 函数将所有确定背景和疑似背景设置为 `0`，其余的设置为 `1`。`np.where` 函数形式如下：\n",
    "\n",
    "```python\n",
    "where(condition, [x, y])\n",
    "```\n",
    "满足条件 (condition)，输出 `x`，不满足输出 `y`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask2 = np.where((mask==2)|(mask==0),0,1).astype('uint8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 18. 显示和保存\n",
    "\n",
    "调用 `cv2.imshow` 显示掩码和提取的背景，并调用 `cv2.imwrite` 进行保存。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"Mask\",mask*80)\n",
    "cv2.imshow(\"Mask2\",mask2*255)\n",
    "cv2.imwrite(result_path+\"mask_07.png\",mask*80)\n",
    "cv2.imwrite(result_path+\"mask2_07.png\",mask2*255)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mask\n",
    "<img src=\"img/mask_07.png\" width=\"15%\">\n",
    "\n",
    "Mask2\n",
    "<img src=\"img/mask2_07.png\" width=\"15%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 19. 保留前景\n",
    "\n",
    "由于掩码为黑色，像素值为 `0`，将蒙版图像与原始图像相乘，原图像中的背景区域像素值与蒙版的 `0` 相乘，全部归零。\n",
    "\n",
    "于是，图像运算结果便只保留了前景图像，而背景变成了黑色，即像素值为 `0`。\n",
    "\n",
    "我们使用以下代码实现:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = img*mask2[:,:,np.newaxis]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20. 备份前景和背景"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_mask = img.copy()\n",
    "mask2 = mask2*255\n",
    "mask_copy = mask2.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 21. 利用 Sketcher 类创建草图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sketch = Sketcher('image', [img_mask, mask2], lambda : ((255,0,0), 255))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 22. 鼠标操作\n",
    "\n",
    "创建一个无限的 while 循环，因为我们想要修改掩码和结果。当按住鼠标左键在 `mask` 上进行滑动时，`mask2` 会跟着进行直线的绘制。\n",
    "\n",
    "其中 OpenCV 设置了多个按键进行操作转换。\n",
    "\n",
    "- **ESC**：退出\n",
    "- **r**：重新生成草图\n",
    "- **b**：切换为背景\n",
    "- **f**：切换为前景\n",
    "- **根据给出的绘制进行交互式前景提取**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exiting...\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    ch = cv2.waitKey()\n",
    "    \n",
    "    # 按ESC退出\n",
    "    if ch == 27:\n",
    "        print(\"exiting...\")\n",
    "        cv2.imwrite(result_path+\"img_mask_grabcut_07.png\",img_mask)\n",
    "        cv2.imwrite(result_path+\"mask_grabcut_07.png\",mask2)\n",
    "        break\n",
    "    \n",
    "    # 重置\n",
    "    elif ch == ord('r'):\n",
    "        print(\"resetting...\")\n",
    "        img_mask = img.copy()\n",
    "        mask2 = mask_copy.copy()\n",
    "        sketch = Sketcher('image', [img_mask, mask2], lambda : ((255,0,0), 255))\n",
    "        sketch.show()\n",
    "    \n",
    "    # 切换到背景\n",
    "    elif ch == ord('b'):\n",
    "        print(\"drawing background...\")\n",
    "        sketch = Sketcher('image', [img_mask, mask2], lambda : ((0,0,255), 0))\n",
    "        sketch.show()\n",
    "    \n",
    "    # 切换到前景\n",
    "    elif ch == ord('f'):\n",
    "        print(\"drawing foreground...\")\n",
    "        sketch = Sketcher('image', [img_mask, mask2], lambda : ((255,0,0), 255))\n",
    "        sketch.show()\n",
    "    else:\n",
    "        print(\"performing grabcut...\")\n",
    "        mask2 = mask2//255\n",
    "        cv2.grabCut(img,mask2,None,bgdModel,fgdModel,5,cv2.GC_INIT_WITH_MASK)\n",
    "        mask2 = np.where((mask2==2)|(mask2==0),0,1).astype('uint8')\n",
    "        img_mask = img*mask2[:,:,np.newaxis]\n",
    "        mask2 = mask2*255\n",
    "        print(\"switching bank to foreground...\")\n",
    "        sketch = Sketcher('image', [img_mask, mask2], lambda : ((255,0,0), 255))\n",
    "        sketch.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 键盘按 **`r`** 时，两张图同时重置\n",
    "<img src=\"img/all_img_07.png\" width=\"40%\">\n",
    "\n",
    "\n",
    "- 按键按 **`b`** 时，切换到背景，背景校正用红色表示。标记区域包括真正属于背景但被 GrabCut 标记为前景的区域。这些区域将在掩膜中标记为黑色。此时在一张图的背景操作，`mask` 也会跟着显示出来，而在前景是无效的。\n",
    "<img src=\"img/back_07.png\" width=\"40%\">\n",
    "\n",
    "\n",
    "- 按键按 **`f`** 时，切换到前景，前景区域校正用蓝色标记，用它覆盖前景区域掩膜中出现的黑色点。蓝色标记的区域现在将成为蒙版中前景的一部分，这意味着它们现在将在蒙版中变成白色，此时在一张图的前景操作，`mask` 也会跟着显示出来，而在背景是无效的。\n",
    "<img src=\"img/fore_07.png\" width=\"40%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 23. 关闭所有窗口"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
